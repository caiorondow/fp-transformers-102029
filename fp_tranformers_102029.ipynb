{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "TI-9zzptD63D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SFx4iuTqCCoS"
      },
      "outputs": [],
      "source": [
        "image_sz = 32\n",
        "batch_sz = 32\n",
        "channel_sz = 3\n",
        "patch_sz = 4\n",
        "hidden_sz = 512\n",
        "embed_sz = 512\n",
        "\n",
        "n_epochs = 25\n",
        "n_heads = 8\n",
        "n_layers = 4\n",
        "n_classes = 10\n",
        "\n",
        "learning_rate = 0.0005\n",
        "\n",
        "dropout = 0.2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "WoKyrWhpQp2l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multi-head attention block"
      ],
      "metadata": {
        "id": "d-u6bTPwC7bg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MHAttention(nn.Module):\n",
        "\n",
        "    def __init__(self, n_heads, embed_sz, dropout, batch_sz):\n",
        "        super(MHAttention, self).__init__()\n",
        "\n",
        "        # attention params\n",
        "        self.n_heads  = n_heads\n",
        "        self.embed_sz = embed_sz\n",
        "        self.dropout  = dropout\n",
        "        self.batch_sz = batch_sz\n",
        "        self.head_sz  = embed_sz // n_heads\n",
        "\n",
        "        self.dropout_lr = nn.Dropout(dropout)\n",
        "\n",
        "        self.Q = nn.Linear(self.embed_sz, self.embed_sz)\n",
        "        self.K = nn.Linear(self.embed_sz, self.embed_sz)\n",
        "        self.V = nn.Linear(self.embed_sz, self.embed_sz)\n",
        "\n",
        "        self.l = nn.Linear(self.embed_sz, self.embed_sz)\n",
        "\n",
        "    def forward(self, q, k, v, mask = None):\n",
        "\n",
        "        q0, q1, q2 = q.size()\n",
        "        k0, k1, k2 = k.size()\n",
        "        v0, v1, v2 = v.size()\n",
        "\n",
        "        q = self.Q(q).reshape(q0, q1, self.n_heads, self.head_sz)\n",
        "        k = self.Q(k).reshape(k0, k1, self.n_heads, self.head_sz)\n",
        "        v = self.Q(v).reshape(v0, v1, self.n_heads, self.head_sz)\n",
        "\n",
        "        if self.batch_sz == 1:\n",
        "            q = q.transpose(0,1)\n",
        "            k = k.transpose(0,1)\n",
        "            v = v.transpose(0,1)\n",
        "\n",
        "        attention = self.attention(q, k, v, mask)\n",
        "\n",
        "        return self.l( attention.reshape(-1, v1, self.embed_sz) )\n",
        "\n",
        "    def attention(self, q, k, v, mask = None):\n",
        "\n",
        "\n",
        "        scores = torch.einsum(\"bqhe,bkhe->bhqk\", [q, k])\n",
        "\n",
        "        if mask is not None:\n",
        "            scores = scores.masked_fill(mask == 0, -1e9)\n",
        "\n",
        "        scores = scores / math.sqrt(self.embed_sz)\n",
        "        scores = F.softmax(scores, dim = -1)\n",
        "\n",
        "        return torch.einsum(\"bhql,blhd->bqhd\", [scores, v])"
      ],
      "metadata": {
        "id": "9-INQAH3C4ro"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encoder"
      ],
      "metadata": {
        "id": "sgWcTlkEGQyN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ViTEncoder(nn.Module):\n",
        "    def __init__(self, n_heads, embed_sz, dropout, hidden_sz):\n",
        "        super(ViTEncoder, self).__init__()\n",
        "\n",
        "        # attention params\n",
        "        self.n_heads    = n_heads\n",
        "        self.embed_sz   = embed_sz\n",
        "        self.dropout    = dropout\n",
        "        # self.batch_sz = batch_sz\n",
        "        # self.head_sz  = embed_sz // n_heads\n",
        "        self.hidden_sz  = hidden_sz\n",
        "\n",
        "        self.norm1 = nn.LayerNorm(self.embed_sz)\n",
        "        self.norm2 = nn.LayerNorm(self.embed_sz)\n",
        "\n",
        "        self.attention = MHAttention(n_heads, embed_sz, dropout, 0)\n",
        "        self.MLP = nn.Sequential(\n",
        "            nn.Linear(self.embed_sz, 4*self.embed_sz),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(self.dropout),\n",
        "            nn.Linear(4*self.embed_sz, self.embed_sz),\n",
        "            nn.Dropout(self.dropout)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.norm1(x)\n",
        "        x = x + self.attention(x, x, x)\n",
        "        x = x + self.MLP(self.norm2(x))\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "M6TCuo4YGUjx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DeiT"
      ],
      "metadata": {
        "id": "PqCdua7FIFZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DeiT(nn.Module):\n",
        "\n",
        "    def __init__(self,image_sz,channel_sz,patch_sz,hidden_sz,embed_sz,n_heads,n_layers,n_classes,teacher,dropout):\n",
        "        super(DeiT, self).__init__()\n",
        "\n",
        "        self.image_sz        = image_sz\n",
        "        self.channel_sz      = channel_sz\n",
        "        self.patch_sz0       = patch_sz\n",
        "        self.hidden_sz       = hidden_sz\n",
        "        self.embed_sz        = embed_sz\n",
        "        self.n_heads         = n_heads\n",
        "        self.n_layers        = n_layers\n",
        "        self.n_classes       = n_classes\n",
        "        self.teacher         = teacher\n",
        "        self.dropout         = dropout\n",
        "        self.n_patches       = (image_sz // patch_sz) ** 2\n",
        "        self.patch_sz1       = channel_sz * (patch_sz ** 2)\n",
        "        self.dropout_lr      = nn.Dropout(self.dropout)\n",
        "        self.norm1           = nn.LayerNorm(self.embed_sz)\n",
        "        self.distillation_tk = nn.Parameter(torch.randn(1,1,self.embed_sz))\n",
        "        self.class_tk        = nn.Parameter(torch.randn(1,1,self.embed_sz))\n",
        "        self.embed           = nn.Linear(self.patch_sz1, self.embed_sz)\n",
        "        self.pos_encoding    = nn.Parameter(torch.randn(1,self.n_patches + 2, self.embed_sz))\n",
        "\n",
        "        for parameter in self.teacher.parameters():\n",
        "            parameter.requires_grad = False\n",
        "        self.teacher.eval()\n",
        "\n",
        "        self.encoders = nn.ModuleList([])\n",
        "        for layer in range(self.n_layers):\n",
        "            self.encoders.append(ViTEncoder(self.n_heads, self.embed_sz, self.dropout, self.hidden_sz))\n",
        "        self.classifier = nn.Sequential(nn.Linear(self.embed_sz, self.n_classes))\n",
        "\n",
        "    def forward(self, x, mask = None):\n",
        "        b,c,h,w = x.size()\n",
        "\n",
        "        teacher_out = self.teacher(x)\n",
        "        x = x.reshape(b, int((h / self.patch_sz0) * (w / self.patch_sz0)), c * self.patch_sz0 * self.patch_sz0)\n",
        "        x = self.embed(x)\n",
        "        b,n,e = x.size()\n",
        "\n",
        "        class_tk = self.class_tk.expand(b,1,e)\n",
        "        distillation_tk = self.class_tk.expand(b,1,e)\n",
        "\n",
        "        x = torch.cat((class_tk, x), dim=1)\n",
        "        x = torch.cat((x, distillation_tk), dim=1)\n",
        "        x = self.dropout_lr(x+self.pos_encoding)\n",
        "\n",
        "        for enc in self.encoders:\n",
        "            x = enc(x)\n",
        "\n",
        "        x, distillation_token = x[:, 0, :], x[:, -1, :]\n",
        "        x = self.classifier(self.norm1(x))\n",
        "\n",
        "        return self.classifier(self.norm1(x)), teacher_out"
      ],
      "metadata": {
        "id": "0a3TAm6cIH9Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hard distillation loss"
      ],
      "metadata": {
        "id": "E0rOrctBRx3k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class HardDistillationLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(HardDistillationLoss, self).__init__()\n",
        "\n",
        "        self.teacher_cel = nn.CrossEntropyLoss()\n",
        "        self.student_cel = nn.CrossEntropyLoss()\n",
        "\n",
        "    def forward(self, teacher_y, student_y, y):\n",
        "        return 0.5 * ( (self.student_cel(student_y, y)) + (self.teacher_cel(teacher_y, y)) )"
      ],
      "metadata": {
        "id": "0e-v6AO2Rz_O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Teacher"
      ],
      "metadata": {
        "id": "kxgrJylRM8Zf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.autograd import Variable\n",
        "\n",
        "import torchvision\n",
        "import torchvision.models as models\n",
        "\n",
        "import math\n",
        "\n",
        "class VGG16_classifier(nn.Module):\n",
        "    def __init__(self,\n",
        "                 image_sz,\n",
        "                 n_classes,\n",
        "                 hidden_sz,\n",
        "                 dropout\n",
        "                 ):\n",
        "\n",
        "        self.image_sz = image_sz\n",
        "        self.n_classes = n_classes\n",
        "        self.hidden_sz = hidden_sz\n",
        "        self.dropout = dropout\n",
        "\n",
        "        self.vgg16 = models.vgg16(pretrained=True)\n",
        "        for parameter in self.vgg16.parameters():\n",
        "            parameter.requires_grad = True\n",
        "        self.vgg16.classifier = nn.Sequential(\n",
        "                nn.Linear(25088, self.hidden_sz * 4),\n",
        "                nn.ReLU(),\n",
        "                nn.Dropout(self.dropout),\n",
        "                nn.Linear(self.hidden_sz * 4, self.hidden_sz * 2),\n",
        "                nn.ReLU(),\n",
        "                nn.Dropout(self.dropout),\n",
        "                nn.Linear(self.hidden_sz * 2, self.hidden_sz),\n",
        "                nn.ReLU(),\n",
        "                nn.Dropout(self.dropout),\n",
        "                nn.Linear(self.hidden_sz, self.n_classes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.vgg16(x)"
      ],
      "metadata": {
        "id": "tav_mmAYM8LE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "_uBfXeQOQT8z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "teacher = torch.load(\"add/your/path/to/vgg16_cifar10.pth\")"
      ],
      "metadata": {
        "id": "VLoIdfDTM0fD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# define model"
      ],
      "metadata": {
        "id": "prk1ihwMVbEO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = DeiT(\n",
        "    image_sz=image_sz,\n",
        "    channel_sz=channel_sz,\n",
        "    patch_sz=patch_sz,\n",
        "    hidden_sz=hidden_sz,\n",
        "    embed_sz=embed_sz,\n",
        "    n_heads=n_heads,\n",
        "    n_layers=n_layers,\n",
        "    n_classes=n_classes,\n",
        "    teacher=teacher,\n",
        "    dropout=dropout\n",
        ").to(device)"
      ],
      "metadata": {
        "id": "J28xeixPMgtA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train/Test"
      ],
      "metadata": {
        "id": "s0yviSzIT4Me"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, train_loader, loss_function, optimizer, device, num_epochs):\n",
        "\n",
        "    training_history = {\n",
        "        \"accuracy\": [],\n",
        "        \"loss\": []\n",
        "    }\n",
        "\n",
        "    for epoch in range(1, num_epochs + 1):\n",
        "        model.train()\n",
        "\n",
        "        epoch_loss = 0\n",
        "        true_labels = []\n",
        "        predicted_labels = []\n",
        "\n",
        "        for batch_index, (images, labels) in enumerate(train_loader):\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            student_predictions, teacher_predictions = model(images)\n",
        "            loss = loss_function(teacher_predictions, student_predictions, labels)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            predicted_labels.extend(student_predictions.detach().argmax(dim=-1).tolist())\n",
        "            true_labels.extend(labels.detach().tolist())\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "        total_correct = sum(pred == true for pred, true in zip(predicted_labels, true_labels))\n",
        "        total_samples = len(predicted_labels)\n",
        "        accuracy = total_correct * 100 / total_samples\n",
        "\n",
        "        training_history[\"loss\"].append(epoch_loss)\n",
        "        training_history[\"accuracy\"].append(accuracy)\n",
        "\n",
        "        print(f\"{'-' * 50}\")\n",
        "        print(f\"Epoch {epoch}/{num_epochs}\")\n",
        "        print(f\"Train Loss      : {epoch_loss:.6f}\")\n",
        "        print(f\"Train Accuracy  : {accuracy:.2f}% ({total_correct}/{total_samples})\")\n",
        "        print(f\"{'-' * 50}\")\n",
        "\n",
        "    return training_history"
      ],
      "metadata": {
        "id": "WnBXTU0iRso4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model, test_loader, device):\n",
        "\n",
        "    model.eval()\n",
        "    true_labels = []\n",
        "    predicted_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_index, (images, labels) in enumerate(test_loader):\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            predictions, _ = model(images)\n",
        "\n",
        "            predicted_labels.extend(predictions.argmax(dim=-1).tolist())\n",
        "            true_labels.extend(labels.tolist())\n",
        "\n",
        "    total_correct = sum(pred == true for pred, true in zip(predicted_labels, true_labels))\n",
        "    total_samples = len(predicted_labels)\n",
        "    accuracy = total_correct * 100 / total_samples\n",
        "\n",
        "    print(f\"{'-' * 50}\")\n",
        "    print(f\"Test Accuracy   : {accuracy:.2f}% ({total_correct}/{total_samples})\")\n",
        "    print(f\"{'-' * 50}\")\n",
        "\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "VM9O_pUpTtsf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## preprocess cifar10"
      ],
      "metadata": {
        "id": "xpUO982bUEyd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import datasets, transforms\n",
        "\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "\n",
        "trainset = datasets.CIFAR10('../data/CIFAR10/', download=True, train=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_sz, shuffle=True)\n",
        "\n",
        "testset = datasets.CIFAR10('../data/CIFAR10/', download=True, train=False, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_sz, shuffle=False)"
      ],
      "metadata": {
        "id": "Fqdoc_mkUGJ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## exec"
      ],
      "metadata": {
        "id": "iF2lKBEoT6ir"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = HardDistillationLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1)"
      ],
      "metadata": {
        "id": "AJjsxOc7T3C8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(model, trainloader, criterion, optimizer, device, n_epochs)"
      ],
      "metadata": {
        "id": "ykkP6bEiT_Et"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test(model, testloader, device)"
      ],
      "metadata": {
        "id": "KCp_5t2KXfUJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}